{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888e6c0a",
   "metadata": {},
   "source": [
    "# Universidad de las Ciencias Informáticas \n",
    "## Facultad de Tecnologias Educativas \n",
    "### Asignatura: Aprendizaje Automatico\n",
    "\n",
    "---\n",
    "\n",
    "# **Informe del Proceso KDD aplicado al Dataset \"Netflix Titles\" para la Tarea Extraclase**\n",
    "\n",
    "## **Autor:** Frank Ernesto Cortiñas Peña  \n",
    "## **Carrera:** Ingeniería en Ciencias Informáticas  \n",
    "## **Año:** 2025  \n",
    "\n",
    "---\n",
    "\n",
    "## Profesor(a): Stephani de la Caridad   \n",
    "## Grupo: 401  \n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c33db",
   "metadata": {},
   "source": [
    "# 1. Introducción\n",
    "\n",
    "El presente proyecto aplica la metodología KDD (Knowledge Discovery in Databases) al dataset *Netflix Titles*, el cual contiene información descriptiva sobre series y películas disponibles en la plataforma Netflix. El objetivo principal es desarrollar un proceso de descubrimiento de conocimiento que permita construir modelos capaces de clasificar si un título corresponde a una película (*Movie*) o una serie (*TV Show*).\n",
    "\n",
    "El conjunto de datos contiene 8 807 registros y 12 atributos, incluyendo título, reparto, director, país, duración, rating, año de lanzamiento y géneros asociados. La naturaleza de estos atributos combina datos categóricos, numéricos y texto, por lo que es necesario aplicar técnicas de limpieza y transformación.\n",
    "\n",
    "El problema a resolver es de **clasificación supervisada**, utilizando tres algoritmos de minería de datos:\n",
    "\n",
    "- **K-Nearest Neighbors (K-NN)**  \n",
    "  - *Ventajas:* simple, no paramétrico, buena precisión con datos bien distribuidos.  \n",
    "  - *Desventajas:* sensible al ruido, lento con grandes volúmenes.  \n",
    "  - *Aplicaciones:* sistemas de recomendación, reconocimiento de patrones.\n",
    "\n",
    "- **ID3 (DecisionTreeClassifier)**  \n",
    "  - *Ventajas:* fácil de interpretar, no requiere escalamiento, maneja variables categóricas.  \n",
    "  - *Desventajas:* propenso al sobreajuste, sensible a cambios mínimos en los datos.  \n",
    "  - *Aplicaciones:* clasificación en marketing, salud, detección de fraude.\n",
    "\n",
    "- **Random Forest** (algoritmo elegido adicionalmente)  \n",
    "  - *Ventajas:* robusto, reduce sobreajuste, maneja alta dimensionalidad.  \n",
    "  - *Desventajas:*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7937a9",
   "metadata": {},
   "source": [
    "# 2. Selección del Conjunto de Datos\n",
    "\n",
    "El dataset empleado proviene del repositorio público de Kaggle y contiene información sobre títulos publicados en Netflix. Este dataset es adecuado para tareas de clasificación debido a la variable `type` que especifica si un registro es una película (*Movie*) o serie (*TV Show*).\n",
    "\n",
    "A continuación, se cargan y describen las características principales del conjunto de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2efaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.offline import plot\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#import time\n",
    "\n",
    "df = pd.read_csv(\"Data/netflix_titles.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d00de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481685fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a282cb9e",
   "metadata": {},
   "source": [
    "# 2.1 Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "Antes de proceder con el preprocesamiento y modelado, es fundamental comprender la estructura, calidad y características del conjunto de datos. Este análisis exploratorio nos permitirá identificar patrones, valores atípicos, relaciones entre variables y posibles problemas de calidad de datos que deberán abordarse en las etapas posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116dd58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b8f72",
   "metadata": {},
   "source": [
    "# 2.2 Información general del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensiones del dataset\n",
    "print(f\"Dimensiones del dataset: {df.shape[0]} filas y {df.shape[1]} columnas\")\n",
    "\n",
    "# Información básica sobre las columnas\n",
    "print(\"\\nInformación detallada de las columnas:\")\n",
    "df.info()\n",
    "\n",
    "# Estadísticas descriptivas básicas\n",
    "print(\"\\nEstadísticas descriptivas básicas:\")\n",
    "display(df.describe(include='all').T)\n",
    "\n",
    "# Tipos de contenido únicos\n",
    "print(\"\\nTipos de contenido únicos:\")\n",
    "print(df['type'].value_counts())\n",
    "print(\"\\nProporción de tipos de contenido:\")\n",
    "print(df['type'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19af1832",
   "metadata": {},
   "source": [
    "# 2.3 Análisis de valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de valores faltantes\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Mapa de calor de valores faltantes', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('missing_values_heatmap.png')\n",
    "plt.show()\n",
    "\n",
    "# Porcentaje de valores faltantes por columna\n",
    "missing_values = df.isnull().sum().sort_values(ascending=False)\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "missing_df = pd.DataFrame({'Valores faltantes': missing_values, 'Porcentaje (%)': missing_percent})\n",
    "missing_df = missing_df[missing_df['Valores faltantes'] > 0]\n",
    "\n",
    "print(\"Columnas con valores faltantes:\")\n",
    "display(missing_df)\n",
    "\n",
    "# Visualización del porcentaje de valores faltantes\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=missing_df.index, y=missing_df['Porcentaje (%)'])\n",
    "plt.title('Porcentaje de valores faltantes por columna', fontsize=16)\n",
    "plt.ylabel('Porcentaje (%)')\n",
    "plt.xlabel('Columnas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('missing_values_percentage.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0fec03",
   "metadata": {},
   "source": [
    "# 2.4 Análisis de variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de la variable 'country' (países de producción)\n",
    "# Limpieza y preparación para el análisis\n",
    "country_data = df['country'].dropna().str.split(',').explode().str.strip()\n",
    "top_countries = country_data.value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x=top_countries.values, y=top_countries.index, palette='viridis')\n",
    "plt.title('Top 10 países productores de contenido en Netflix', fontsize=16)\n",
    "plt.xlabel('Número de títulos')\n",
    "plt.tight_layout()\n",
    "plt.savefig('top_countries.png')\n",
    "plt.show()\n",
    "\n",
    "# Análisis de 'rating' (clasificación por edades)\n",
    "rating_counts = df['rating'].value_counts().sort_values(ascending=False)\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x=rating_counts.values, y=rating_counts.index, palette='viridis')\n",
    "plt.title('Distribución de clasificaciones por edades', fontsize=16)\n",
    "plt.xlabel('Número de títulos')\n",
    "plt.tight_layout()\n",
    "plt.savefig('rating_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Análisis de 'listed_in' (géneros)\n",
    "categories = df['listed_in'].str.split(',').explode().str.strip().value_counts().head(15)\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x=categories.values, y=categories.index, palette='viridis')\n",
    "plt.title('Top 15 géneros/categorías en Netflix', fontsize=16)\n",
    "plt.xlabel('Número de títulos')\n",
    "plt.tight_layout()\n",
    "plt.savefig('top_genres.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b854d24",
   "metadata": {},
   "source": [
    "# 2.5 Análisis comparativo entre películas y series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215a82d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contenido por tipo (películas vs series)\n",
    "type_counts = df['type'].value_counts()\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', \n",
    "        colors=['#E50914', '#221F1F'], startangle=90, explode=(0.05, 0))\n",
    "plt.title('Proporción de películas y series en Netflix', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('content_type_pie.png')\n",
    "plt.show()\n",
    "\n",
    "# Duración promedio por tipo de contenido\n",
    "# Convertir duración a formato numérico para análisis\n",
    "df['duration_clean'] = df['duration'].str.extract('(\\d+)').astype(float)\n",
    "\n",
    "# Comparar duración entre películas y series\n",
    "movie_duration = df[df['type'] == 'Movie']['duration_clean']\n",
    "tv_show_seasons = df[df['type'] == 'TV Show']['duration_clean']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Histograma para películas (duración en minutos)\n",
    "sns.histplot(movie_duration.dropna(), bins=30, kde=True, ax=ax1, color='#E50914')\n",
    "ax1.set_title('Distribución de duración de películas (minutos)', fontsize=14)\n",
    "ax1.set_xlabel('Duración (minutos)')\n",
    "ax1.set_ylabel('Frecuencia')\n",
    "\n",
    "# Histograma para series (número de temporadas)\n",
    "sns.histplot(tv_show_seasons.dropna(), bins=15, kde=True, ax=ax2, color='#221F1F')\n",
    "ax2.set_title('Distribución de temporadas en series', fontsize=14)\n",
    "ax2.set_xlabel('Número de temporadas')\n",
    "ax2.set_ylabel('Frecuencia')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('duration_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "# Países de producción por tipo de contenido\n",
    "country_data_type = df.dropna(subset=['country']).copy()\n",
    "country_data_type['country_list'] = country_data_type['country'].str.split(',')\n",
    "country_data_type = country_data_type.explode('country_list')\n",
    "country_data_type['country_clean'] = country_data_type['country_list'].str.strip()\n",
    "\n",
    "top_countries_by_type = country_data_type.groupby('type')['country_clean'].value_counts().groupby(level=0).nlargest(5).reset_index(level=0, drop=True).reset_index()\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(data=top_countries_by_type, x='country_clean', y='country_clean', hue='type', estimator=lambda x: len(x), errorbar=None)\n",
    "plt.title('Top 5 países de producción por tipo de contenido', fontsize=16)\n",
    "plt.xlabel('País')\n",
    "plt.ylabel('Número de títulos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Tipo de contenido')\n",
    "plt.tight_layout()\n",
    "plt.savefig('countries_by_type.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0120197",
   "metadata": {},
   "source": [
    "# 2.6 Análisis de relaciones entre variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa788f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación entre variables numéricas\n",
    "num_df = df[['release_year', 'duration_clean']].dropna()\n",
    "num_df['type_encoded'] = df['type'].map({'Movie': 0, 'TV Show': 1})\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(num_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Matriz de correlación entre variables numéricas', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864f2d16",
   "metadata": {},
   "source": [
    "# 2.7 Conclusiones del EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea79ca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen de hallazgos clave\n",
    "print(\"Resumen de hallazgos clave del Análisis Exploratorio:\\n\")\n",
    "\n",
    "# 1. Calidad de datos\n",
    "missing_summary = df.isnull().mean() * 100\n",
    "high_missing = missing_summary[missing_summary > 20]\n",
    "if not high_missing.empty:\n",
    "    print(f\"1. Calidad de datos: Se identificaron columnas con más del 20% de valores faltantes:\")\n",
    "    for col, percent in high_missing.items():\n",
    "        print(f\"   - {col}: {percent:.1f}% de valores faltantes\")\n",
    "else:\n",
    "    print(\"1. Calidad de datos: No se encontraron columnas con más del 20% de valores faltantes\")\n",
    "\n",
    "# 2. Distribución de contenido\n",
    "movie_pct = (df['type'].value_counts()['Movie'] / len(df)) * 100\n",
    "tvshow_pct = (df['type'].value_counts()['TV Show'] / len(df)) * 100\n",
    "print(f\"\\n2. Distribución de contenido:\")\n",
    "print(f\"   - Películas: {movie_pct:.1f}% del catálogo\")\n",
    "print(f\"   - Series: {tvshow_pct:.1f}% del catálogo\")\n",
    "\n",
    "\n",
    "\n",
    "# 3. Países productores\n",
    "top_country = country_data.value_counts().index[0]\n",
    "top_country_count = country_data.value_counts().iloc[0]\n",
    "print(f\"\\n4. Producción global:\")\n",
    "print(f\"   - {top_country} es el principal país productor con {top_country_count} títulos\")\n",
    "print(f\"   - Netflix muestra una diversidad significativa de contenido internacional\")\n",
    "\n",
    "# 5. Distribución de géneros\n",
    "top_genre = categories.index[0]\n",
    "top_genre_count = categories.iloc[0]\n",
    "print(f\"\\n5. Géneros predominantes:\")\n",
    "print(f\"   - '{top_genre}' es el género más común con {top_genre_count} títulos\")\n",
    "\n",
    "# 6. Recomendaciones para preprocesamiento\n",
    "print(\"\\n6. Recomendaciones para preprocesamiento:\")\n",
    "print(\"   - Manejo de valores faltantes en columnas críticas como 'director', 'country' y 'cast'\")\n",
    "print(\"   - Procesamiento de texto para columnas con múltiples valores (country, listed_in, cast)\")\n",
    "print(\"   - Transformación de variables temporales para análisis más detallado\")\n",
    "print(\"   - Codificación de variables categóricas para modelado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c8bfa",
   "metadata": {},
   "source": [
    "El análisis exploratorio realizado ha proporcionado una comprensión profunda del conjunto de datos de Netflix, identificando sus características principales, calidad de datos y patrones significativos. Estos hallazgos serán fundamentales para guiar las decisiones en la etapa de preprocesamiento y para la selección de características relevantes para el modelo de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dbdc11",
   "metadata": {},
   "source": [
    "# 3. Preprocesamiento de los Datos\n",
    "\n",
    "En esta etapa se identifican valores faltantes, se eliminan o transforman atributos no útiles, y se prepara la base para su modelado.\n",
    "\n",
    "Se realizaron los siguientes pasos:\n",
    "- Eliminación de columnas irrelevantes para la clasificación.\n",
    "- Limpieza de valores nulos.\n",
    "- Transformación de variables categóricas.\n",
    "- Conversión de `duration` a formato numérico (minutos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0164d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4914232",
   "metadata": {},
   "source": [
    "## Eliminación de columnas irrelevantes para la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminacion de columnas irrelevantes\n",
    "df_clean = df.drop(columns=[\"show_id\", \"description\", \"cast\", \"director\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483f07a5",
   "metadata": {},
   "source": [
    "## Limpieza de valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nulos\n",
    "df_clean = df_clean.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c96a12d",
   "metadata": {},
   "source": [
    "## Transformación de variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ad554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asegurar que la columna sea string\n",
    "df_clean[\"duration\"] = df_clean[\"duration\"].astype(str)\n",
    "\n",
    "# extraer el numero (sin warnings)\n",
    "df_clean[\"duration\"] = df_clean[\"duration\"].str.extract(r\"(\\d+)\")\n",
    "\n",
    "# convertir a entero (coerce evita errores)\n",
    "df_clean[\"duration\"] = pd.to_numeric(df_clean[\"duration\"], errors='coerce')\n",
    "\n",
    "# eliminar valores NaN reventao\n",
    "df_clean = df_clean.dropna(subset=[\"duration\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe60ca",
   "metadata": {},
   "source": [
    "## Muestrario de Avance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8484a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e17aac4",
   "metadata": {},
   "source": [
    "# 4. Transformación de los Datos\n",
    "\n",
    "Para poder entrenar los modelos de aprendizaje automático, es necesario transformar los datos a un formato numérico que los algoritmos puedan procesar. Las variables categóricas, como type, country, rating y listed_in, deben ser codificadas adecuadamente ya que los modelos no pueden interpretar valores de texto directamente. En esta etapa se aplican dos técnicas fundamentales de codificación:\n",
    "\n",
    "- Label Encoding a type: Dado que la variable objetivo (type) es binaria (solo contiene dos categorías: \"Movie\" y \"TV Show\"), se utiliza Label Encoding para convertirla a valores numéricos (0 y 1). Esta técnica asigna un valor entero único a cada categoría, transformando \"Movie\" en 0 y \"TV Show\" en 1. Es apropiada para la variable objetivo en problemas de clasificación binaria ya que mantiene la información de clase sin aumentar la dimensionalidad del dataset.\n",
    "- One Hot Encoding al resto de variables categóricas: Para las variables predictoras categóricas (country, rating, listed_in, etc.), se aplica One Hot Encoding, que crea nuevas columnas binarias (0/1) para cada posible valor de la variable original. Por ejemplo, para la variable country, se crearían columnas como country_United States, country_India, country_Spain, etc., donde un 1 indica que el título pertenece a ese país y 0 en caso contrario. Esta técnica es preferible para variables predictoras porque evita que el modelo interprete relaciones ordinales inexistentes entre categorías (como si \"Estados Unidos\" > \"México\" numéricamente).\n",
    "\n",
    "### Este proceso de transformación tiene importantes implicaciones:\n",
    "\n",
    "- Aumento dimensional: One Hot Encoding puede incrementar significativamente el número de características, especialmente para variables con muchos valores únicos como country o listed_in.\n",
    "- Eliminación de multicolinealidad: Se aplica el parámetro drop_first=True para eliminar una columna de cada variable categórica transformada, evitando problemas de multicolinealidad donde una columna puede predecirse perfectamente a partir de otras.\n",
    "- Preservación de información: A diferencia de otras técnicas de codificación, One Hot Encoding preserva completamente la información categórica sin introducir relaciones numéricas artificiales.\n",
    "\n",
    "### Finalmente se separan los conjuntos X e Y:\n",
    "\n",
    "X contiene todas las características predictoras (variables independientes) transformadas numéricamente\n",
    "y contiene únicamente la variable objetivo (type) codificada con Label Encoding\n",
    "Esta separación es fundamental para el proceso de entrenamiento supervisado, permitiendo que los algoritmos aprendan la relación entre las características de entrada (X) y la variable objetivo (y) que se desea predecir. El resultado es un dataset completamente numérico, listo para ser procesado por los algoritmos de aprendizaje automático en la siguiente etapa del proceso KDD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e17d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# codificación de la variable objetivo ()\n",
    "encoder = LabelEncoder()\n",
    "df_clean[\"type\"] = encoder.fit_transform(df_clean[\"type\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef1b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "df_model = pd.get_dummies(df_clean, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940cab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop(columns=[\"type\"])\n",
    "y = df_model[\"type\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcefec94",
   "metadata": {},
   "source": [
    "# 5. Minería de Datos\n",
    "\n",
    "En esta etapa se entrenan los tres algoritmos seleccionados para el problema de clasificación binaria (distinguir entre películas y series de TV):\n",
    "\n",
    "- **K-Nearest Neighbors (KNN)**\n",
    "- **Árbol de Decisión (ID3)**\n",
    "- **Random Forest**\n",
    "\n",
    "Todos los modelos son evaluados sobre el mismo conjunto de entrenamiento y prueba para garantizar una comparación justa. A continuación, se detalla cada algoritmo con sus fundamentos matemáticos, ventajas, desventajas y aplicaciones prácticas.\n",
    "\n",
    "## K-Nearest Neighbors (KNN)\n",
    "\n",
    "**Fundamentos matemáticos:**  \n",
    "KNN es un algoritmo de aprendizaje supervisado basado en instancia. Para clasificar un nuevo punto, KNN identifica los K puntos más cercanos en el espacio de características y asigna la clase predominante entre ellos. La distancia se calcula comúnmente usando la distancia euclidiana:\n",
    "\n",
    "$$d(x, x_i) = \\sqrt{\\sum_{j=1}^{n}(x_j - x_{i,j})^2}$$\n",
    "\n",
    "Donde $x$ es el vector de características del nuevo punto, $x_i$ es el vector de características del punto $i$ en el conjunto de entrenamiento, y $n$ es el número de características.\n",
    "\n",
    "**Ventajas:**\n",
    "- Simple de implementar e interpretar\n",
    "- No requiere fase de entrenamiento explícita (perezoso)\n",
    "- Funciona bien con fronteras de decisión no lineales\n",
    "- Adaptable a nuevos datos sin reentrenamiento completo\n",
    "\n",
    "**Desventajas:**\n",
    "- Costo computacional alto durante la predicción (O(n))\n",
    "- Sensible a características irrelevantes o con diferentes escalas\n",
    "- Requiere normalización de datos\n",
    "- Elección crítica del parámetro K\n",
    "\n",
    "**Aplicaciones prácticas:**  \n",
    "KNN se utiliza frecuentemente en sistemas de recomendación (como Netflix), reconocimiento de patrones, diagnóstico médico y clasificación de imágenes. Por ejemplo, Netflix podría usar KNN para recomendar películas similares basándose en las características de visualización de usuarios con gustos similares.\n",
    "\n",
    "**Relevancia para este problema:**  \n",
    "KNN es adecuado para nuestro problema porque puede identificar patrones en las características de películas y series (duración, país de origen, géneros) sin asumir una distribución específica de los datos.\n",
    "\n",
    "## Árbol de Decisión (ID3)\n",
    "\n",
    "**Fundamentos matemáticos:**  \n",
    "ID3 (Iterative Dichotomiser 3) construye un árbol de decisión mediante división recursiva de los datos usando el concepto de entropía e información ganada. La entropía mide la impureza de un conjunto:\n",
    "\n",
    "$$H(S) = -\\sum_{i=1}^{c} p_i \\log_2 p_i$$\n",
    "\n",
    "Donde $S$ es el conjunto de datos, $c$ es el número de clases y $p_i$ es la proporción de elementos de clase $i$ en $S$.\n",
    "\n",
    "La ganancia de información para un atributo $A$ se calcula como:\n",
    "\n",
    "$$IG(S, A) = H(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} H(S_v)$$\n",
    "\n",
    "Donde $S_v$ es el subconjunto de $S$ para el cual el atributo $A$ tiene valor $v$.\n",
    "\n",
    "**Ventajas:**\n",
    "- Fácil de entender e interpretar visualmente\n",
    "- No requiere normalización de datos\n",
    "- Maneja tanto variables numéricas como categóricas\n",
    "- Identifica características importantes para la predicción\n",
    "- Robusto a valores atípicos\n",
    "\n",
    "**Desventajas:**\n",
    "- Propenso al sobreajuste sin poda adecuada\n",
    "- Inestable (pequeños cambios en datos causan árboles diferentes)\n",
    "- Puede crear árboles sesgados con variables dominantes\n",
    "- No siempre genera el árbol óptimo globalmente\n",
    "\n",
    "**Aplicaciones prácticas:**  \n",
    "Los árboles de decisión se utilizan en diagnóstico médico (identificar enfermedades basadas en síntomas), evaluación crediticia (aprobar/rechazar préstamos), minería de datos empresariales y detección de fraude. Por ejemplo, un banco podría usar un árbol de decisión para determinar si aprobar un préstamo basándose en ingresos, historial crediticio y edad del solicitante.\n",
    "\n",
    "**Relevancia para este problema:**  \n",
    "ID3 es útil para nuestro problema porque puede capturar reglas interpretables como \"si la duración es mayor a 60 minutos y el país es Estados Unidos, entonces es probable que sea una película\", lo que permite comprender los factores que distinguen películas de series.\n",
    "\n",
    "## Random Forest\n",
    "\n",
    "**Fundamentos matemáticos:**  \n",
    "Random Forest es un ensemble method que combina múltiples árboles de decisión entrenados con muestras bootstrap del conjunto de datos original (bagging) y seleccionando aleatoriamente un subconjunto de características en cada división. La predicción final se obtiene por votación mayoritaria:\n",
    "\n",
    "$$f_{RF}(x) = \\text{mode}\\{f_{T_1}(x), f_{T_2}(x), \\dots, f_{T_n}(x)\\}$$\n",
    "\n",
    "Donde $f_{T_i}(x)$ es la predicción del árbol $i$ y $n$ es el número total de árboles.\n",
    "\n",
    "El error del ensemble se relaciona con la correlación entre árboles y su fuerza individual:\n",
    "\n",
    "$$Error_{RF} \\approx \\bar{\\rho} \\sqrt{E_i(1-E_i)}$$\n",
    "\n",
    "Donde $\\bar{\\rho}$ es la correlación promedio entre pares de árboles y $E_i$ es el error promedio de cada árbol individual.\n",
    "\n",
    "**Ventajas:**\n",
    "- Alta precisión y robustez\n",
    "- Reduce significativamente el sobreajuste respecto a árboles individuales\n",
    "- Maneja alta dimensionalidad y características irrelevantes\n",
    "- Proporciona métricas de importancia de características\n",
    "- Paralelizable (entrenamiento eficiente)\n",
    "- No requiere validación cruzada para selección de parámetros\n",
    "\n",
    "**Desventajas:**\n",
    "- Menos interpretable que un solo árbol de decisión\n",
    "- Requiere más recursos computacionales\n",
    "- Puede sobreajustar en datos ruidosos o con alta dimensionalidad\n",
    "- Tiempo de predicción más lento que modelos más simples\n",
    "\n",
    "**Aplicaciones prácticas:**  \n",
    "Random Forest se utiliza ampliamente en bioinformática (identificación de genes relevantes), finanzas (detección de fraudes), visión por computadora (reconocimiento de imágenes), y sistemas de recomendación. Un ejemplo concreto es la detección de transacciones fraudulentas en tarjetas de crédito, donde múltiples árboles pueden identificar patrones complejos de comportamiento fraudulento.\n",
    "\n",
    "**Relevancia para este problema:**  \n",
    "Random Forest es particularmente adecuado para nuestro problema debido a la naturaleza heterogénea de las características del dataset (categóricas como país y género, numéricas como duración y año de lanzamiento). Su capacidad para manejar características correlacionadas y su robustez ante valores faltantes lo hacen ideal para analizar el catálogo diverso de Netflix.\n",
    "\n",
    "## Proceso de Evaluación\n",
    "\n",
    "Para garantizar una comparación justa, todos los modelos se entrenan y evalúan usando la misma división de datos (70% entrenamiento, 30% prueba) y las mismas métricas de evaluación (precision, recall, F1-score, accuracy). La aleatoriedad en la división de datos se controla mediante una semilla fija (random_state=42) para garantizar reproducibilidad de los resultados.\n",
    "\n",
    "Este enfoque sistemático permite identificar qué algoritmo proporciona el mejor rendimiento para la tarea específica de clasificación de contenido de Netflix, considerando tanto la precisión como la capacidad de generalización a nuevos datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664cebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce6390",
   "metadata": {},
   "source": [
    "### En esta etapa se entrenan los tres algoritmos seleccionados con visualizaciones que muestran su funcionamiento interno:\n",
    "\n",
    "- K-Nearest Neighbors (KNN): Visualización de fronteras de decisión y vecinos más cercanos\n",
    "- Árbol de Decisión (ID3): Representación gráfica de la estructura del árbol\n",
    "- Random Forest: Análisis de importancia de características y visualización de árboles individuales\n",
    "\n",
    "Todos los modelos son evaluados sobre el mismo conjunto de entrenamiento y prueba. Las visualizaciones se generan automáticamente durante el entrenamiento para facilitar la comprensión de cómo cada algoritmo procesa los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7a52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "from IPython.display import Image, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración visual\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"Set2\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# División de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalado de datos para visualización\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Reducción de dimensionalidad para visualización\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Colores para las clases\n",
    "colors = ['red', 'blue']  # Movie=0 (rojo), TV Show=1 (azul)\n",
    "class_names = ['Movie', 'TV Show']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c21a81e",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e01c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ENTRENANDO MODELO KNN (K=5)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluación\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"\\nPrecisión del modelo KNN: {acc_knn:.6f}\")\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred_knn, target_names=class_names))\n",
    "\n",
    "# === VISUALIZACIONES KNN ===\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))\n",
    "\n",
    "# 1. Visualización de los datos en el espacio PCA\n",
    "scatter = ax1.scatter(X_train_pca[:, 0], X_train_pca[:, 1], \n",
    "                     c=y_train, cmap='coolwarm', alpha=0.6, s=30)\n",
    "ax1.set_title('Distribución de datos en espacio PCA (Entrenamiento)', fontsize=14)\n",
    "ax1.set_xlabel('Componente Principal 1')\n",
    "ax1.set_ylabel('Componente Principal 2')\n",
    "ax1.legend(handles=scatter.legend_elements()[0], labels=class_names)\n",
    "\n",
    "# 2. Fronteras de decisión (con cuadrícula reducida y muestreo para evitar problemas de memoria)\n",
    "# Aumentar el tamaño del paso para reducir el número de puntos en la cuadrícula\n",
    "h = 0.1  # paso de la cuadrícula más grande (menos puntos)\n",
    "x_min, x_max = X_train_pca[:, 0].min() - 1, X_train_pca[:, 0].max() + 1\n",
    "y_min, y_max = X_train_pca[:, 1].min() - 1, X_train_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Crear matriz para los resultados (inicializada con un valor por defecto)\n",
    "Z = np.zeros_like(xx)\n",
    "\n",
    "# Muestrear puntos estratégicos para la predicción\n",
    "# Convertir los puntos de la cuadrícula a formato adecuado\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# Limitar el número de puntos para predecir (muestreo aleatorio)\n",
    "max_points = 5000  # Límite razonable para evitar problemas de memoria\n",
    "if len(grid_points) > max_points:\n",
    "    indices = np.random.choice(len(grid_points), max_points, replace=False)\n",
    "    sampled_points = grid_points[indices]\n",
    "    \n",
    "    # Predecir solo para los puntos muestreados\n",
    "    original_space_samples = pca.inverse_transform(sampled_points)\n",
    "    Z_sampled = knn.predict(original_space_samples)\n",
    "    \n",
    "    # Crear una matriz completa con los resultados muestreados\n",
    "    Z_flat = np.zeros(len(grid_points))\n",
    "    Z_flat[indices] = Z_sampled\n",
    "    Z = Z_flat.reshape(xx.shape)\n",
    "else:\n",
    "    # Si hay pocos puntos, predecir para todos\n",
    "    original_space_samples = pca.inverse_transform(grid_points)\n",
    "    Z_flat = knn.predict(original_space_samples)\n",
    "    Z = Z_flat.reshape(xx.shape)\n",
    "\n",
    "# Contorno de las fronteras de decisión (basado en muestreo)\n",
    "contour = ax2.contourf(xx, yy, Z, cmap='coolwarm', alpha=0.3)\n",
    "ax2.scatter(X_train_pca[:, 0], X_train_pca[:, 1], \n",
    "           c=y_train, cmap='coolwarm', alpha=0.8, s=30)\n",
    "ax2.set_title('Fronteras de Decisión de KNN (k=5) - Muestreo', fontsize=14)\n",
    "ax2.set_xlabel('Componente Principal 1')\n",
    "ax2.set_ylabel('Componente Principal 2')\n",
    "ax2.legend(handles=scatter.legend_elements()[0], labels=class_names)\n",
    "\n",
    "# 3. Ejemplo de vecinos más cercanos para un punto de prueba\n",
    "sample_idx = 0\n",
    "sample_point = X_test_pca[sample_idx].reshape(1, -1)\n",
    "sample_class = y_test.iloc[sample_idx]\n",
    "\n",
    "# Encontrar los 5 vecinos más cercanos en el espacio original\n",
    "distances, indices = knn.kneighbors(X_test.iloc[sample_idx:sample_idx+1])\n",
    "neighbors_classes = y_train.iloc[indices[0]]\n",
    "\n",
    "# Mostrar el punto de prueba y sus vecinos\n",
    "ax3.scatter(X_train_pca[:, 0], X_train_pca[:, 1], \n",
    "           c=y_train, cmap='coolwarm', alpha=0.3, s=20)\n",
    "ax3.scatter(X_test_pca[sample_idx, 0], X_test_pca[sample_idx, 1], \n",
    "           c='green', marker='X', s=200, label='Punto de prueba')\n",
    "    \n",
    "# Marcar los vecinos más cercanos\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    ax3.scatter(X_train_pca[idx, 0], X_train_pca[idx, 1], \n",
    "               edgecolor='black', facecolor='none', s=200, linewidth=2,\n",
    "               label=f'Vecino {i+1} ({class_names[neighbors_classes.iloc[i]]})')\n",
    "\n",
    "ax3.set_title(f'KNN: Vecinos más cercanos para un punto de prueba\\nClase real: {class_names[sample_class]}', fontsize=14)\n",
    "ax3.set_xlabel('Componente Principal 1')\n",
    "ax3.set_ylabel('Componente Principal 2')\n",
    "ax3.legend(loc='best')\n",
    "\n",
    "# 4. Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred_knn)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax4,\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "ax4.set_title('Matriz de Confusión - KNN', fontsize=14)\n",
    "ax4.set_xlabel('Predicción')\n",
    "ax4.set_ylabel('Valor Real')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('knn_visualizations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 5. Gráfico interactivo adicional: Distancia promedio por clase\n",
    "# Optimizar cálculo limitando el número de puntos a comparar\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Limitar el número de puntos para calcular distancias (para evitar problemas de memoria)\n",
    "max_samples = 1000\n",
    "if len(X_train_pca) > max_samples:\n",
    "    indices = np.random.choice(len(X_train_pca), max_samples, replace=False)\n",
    "    X_sample = X_train_pca[indices]\n",
    "    y_sample = y_train.iloc[indices].values\n",
    "else:\n",
    "    X_sample = X_train_pca\n",
    "    y_sample = y_train.values\n",
    "\n",
    "# Calcular distancias promedio entre puntos de la misma clase y de clases diferentes\n",
    "same_class_dists = []\n",
    "diff_class_dists = []\n",
    "\n",
    "# Límite adicional para evitar bucles muy grandes\n",
    "max_comparisons = 50000\n",
    "count = 0\n",
    "\n",
    "for i in range(len(X_sample)):\n",
    "    if count >= max_comparisons:\n",
    "        break\n",
    "    for j in range(i+1, len(X_sample)):\n",
    "        if count >= max_comparisons:\n",
    "            break\n",
    "        dist = np.linalg.norm(X_sample[i] - X_sample[j])\n",
    "        if y_sample[i] == y_sample[j]:\n",
    "            same_class_dists.append(dist)\n",
    "        else:\n",
    "            diff_class_dists.append(dist)\n",
    "        count += 1\n",
    "\n",
    "plt.hist(same_class_dists, bins=30, alpha=0.7, label='Distancia entre misma clase', color='green')\n",
    "plt.hist(diff_class_dists, bins=30, alpha=0.7, label='Distancia entre diferentes clases', color='red')\n",
    "plt.title('Distribución de distancias entre puntos (muestreo)', fontsize=14)\n",
    "plt.xlabel('Distancia euclidiana')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig('knn_distance_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638f776",
   "metadata": {},
   "source": [
    "## Árbol de Decisión (ID3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6218ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ENTRENANDO MODELO ÁRBOL DE DECISIÓN (ID3)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Entrenamiento del modelo con límite de profundidad para mejor visualización\n",
    "id3 = DecisionTreeClassifier(criterion=\"entropy\", max_depth=4, random_state=42)\n",
    "id3.fit(X_train, y_train)\n",
    "y_pred_id3 = id3.predict(X_test)\n",
    "\n",
    "# Evaluación\n",
    "acc_id3 = accuracy_score(y_test, y_pred_id3)\n",
    "print(f\"\\nPrecisión del modelo Árbol de Decisión: {acc_id3:.6f}\")\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred_id3, target_names=class_names))\n",
    "\n",
    "# === VISUALIZACIONES ÁRBOL DE DECISIÓN ===\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 10))\n",
    "\n",
    "# 1. Gráfico de la estructura del árbol\n",
    "plot_tree(id3, \n",
    "          feature_names=X_train.columns.tolist(),\n",
    "          class_names=class_names,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          ax=ax1,\n",
    "          fontsize=8)\n",
    "ax1.set_title('Estructura del Árbol de Decisión (ID3)', fontsize=16)\n",
    "\n",
    "# 2. Importancia de características\n",
    "feature_importance = pd.Series(id3.feature_importances_, index=X_train.columns)\n",
    "feature_importance = feature_importance.sort_values(ascending=False).head(15)  # Top 15 características\n",
    "\n",
    "sns.barplot(x=feature_importance.values, y=feature_importance.index, palette='viridis', ax=ax2)\n",
    "ax2.set_title('Importancia de Características - Árbol de Decisión', fontsize=14)\n",
    "ax2.set_xlabel('Importancia')\n",
    "ax2.set_ylabel('Características')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('decision_tree_visualizations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 3. Visualización de la evolución de la pureza por nivel del árbol\n",
    "plt.figure(figsize=(14, 8))\n",
    "depths = range(1, 6)  # Profundidades de 1 a 5\n",
    "accuracies = []\n",
    "training_errors = []\n",
    "\n",
    "for depth in depths:\n",
    "    tree_temp = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    tree_temp.fit(X_train, y_train)\n",
    "    y_pred_temp = tree_temp.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred_temp))\n",
    "    \n",
    "    # Calcular error de entrenamiento\n",
    "    y_train_pred = tree_temp.predict(X_train)\n",
    "    training_errors.append(1 - accuracy_score(y_train, y_train_pred))\n",
    "\n",
    "plt.plot(depths, accuracies, 'bo-', linewidth=2.5, markersize=10, label='Precisión en Prueba')\n",
    "plt.plot(depths, training_errors, 'ro-', linewidth=2.5, markersize=10, label='Error en Entrenamiento')\n",
    "plt.title('Evolución del rendimiento por profundidad del árbol', fontsize=14)\n",
    "plt.xlabel('Profundidad máxima del árbol')\n",
    "plt.ylabel('Precisión / Error')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.legend()\n",
    "plt.savefig('decision_tree_depth_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 4. Matriz de confusión\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred_id3)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Matriz de Confusión - Árbol de Decisión', fontsize=14)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.savefig('decision_tree_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 5. Visualización detallada con Graphviz (requiere tener Graphviz instalado)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99491c9",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386df6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Radnom Forest\n",
    "print(\"=\"*60)\n",
    "print(\"ENTRENANDO MODELO RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluación\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"\\nPrecisión del modelo Random Forest: {acc_rf:.6f}\")\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=class_names))\n",
    "\n",
    "# === VISUALIZACIONES RANDOM FOREST ===\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20, 16))\n",
    "\n",
    "# 1. Importancia de características promediada\n",
    "feature_importance_rf = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "feature_importance_rf = feature_importance_rf.sort_values(ascending=False).head(20)  # Top 20\n",
    "\n",
    "sns.barplot(x=feature_importance_rf.values, y=feature_importance_rf.index, palette='viridis', ax=ax1)\n",
    "ax1.set_title('Importancia de Características - Random Forest', fontsize=14)\n",
    "ax1.set_xlabel('Importancia')\n",
    "ax1.set_ylabel('Características')\n",
    "\n",
    "# 2. Comparación de importancia con el árbol de decisión\n",
    "common_features = list(set(feature_importance.head(15).index) & set(feature_importance_rf.head(15).index))\n",
    "if common_features:\n",
    "    comparison_data = pd.DataFrame({\n",
    "        'Árbol de Decisión': feature_importance.loc[common_features].values,\n",
    "        'Random Forest': feature_importance_rf.loc[common_features].values\n",
    "    }, index=common_features)\n",
    "    \n",
    "    comparison_data.plot(kind='barh', ax=ax2, width=0.8)\n",
    "    ax2.set_title('Comparación de Importancia de Características Comunes', fontsize=14)\n",
    "    ax2.set_xlabel('Importancia')\n",
    "    ax2.legend(title='Modelo')\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'No hay características comunes en el top 15', \n",
    "             ha='center', va='center', fontsize=12)\n",
    "    ax2.set_title('Comparación de Importancia de Características Comunes', fontsize=14)\n",
    "    ax2.axis('off')\n",
    "\n",
    "# 3. Distribución de profundidades de los árboles\n",
    "depths = [estimator.tree_.max_depth for estimator in rf.estimators_]\n",
    "ax3.hist(depths, bins=20, color='skyblue', edgecolor='black')\n",
    "ax3.set_title('Distribución de Profundidades de los Árboles', fontsize=14)\n",
    "ax3.set_xlabel('Profundidad')\n",
    "ax3.set_ylabel('Número de Árboles')\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# 4. Precisión por número de árboles\n",
    "accuracies = []\n",
    "for i in range(1, 101, 5):\n",
    "    rf_temp = RandomForestClassifier(n_estimators=i, random_state=42, n_jobs=-1)\n",
    "    rf_temp.fit(X_train, y_train)\n",
    "    y_pred_temp = rf_temp.predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, y_pred_temp))\n",
    "\n",
    "ax4.plot(range(1, 101, 5), accuracies, 'b.-', linewidth=2, markersize=10)\n",
    "ax4.set_title('Precisión vs Número de Árboles', fontsize=14)\n",
    "ax4.set_xlabel('Número de Árboles')\n",
    "ax4.set_ylabel('Precisión')\n",
    "ax4.grid(alpha=0.3)\n",
    "ax4.set_ylim(min(accuracies)-0.01, max(accuracies)+0.01)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('random_forest_visualizations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 5. Visualización de un árbol individual del bosque\n",
    "plt.figure(figsize=(20, 10))\n",
    "sample_tree_idx = 0  # Índice del árbol que queremos visualizar\n",
    "sample_tree = rf.estimators_[sample_tree_idx]\n",
    "\n",
    "plot_tree(sample_tree,\n",
    "          feature_names=X_train.columns.tolist(),\n",
    "          class_names=class_names,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=6)\n",
    "plt.title(f'Árbol #{sample_tree_idx+1} del Bosque Aleatorio', fontsize=16)\n",
    "plt.savefig('random_forest_sample_tree.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 6. Matriz de confusión\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Matriz de Confusión - Random Forest', fontsize=14)\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.savefig('random_forest_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 7. Visualización de la distribución de votos para muestras incorrectas\n",
    "incorrect_indices = np.where(y_test != y_pred_rf)[0]\n",
    "if len(incorrect_indices) > 0:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Tomar las primeras 5 predicciones incorrectas\n",
    "    sample_size = min(5, len(incorrect_indices))\n",
    "    sample_indices = incorrect_indices[:sample_size]\n",
    "    \n",
    "    vote_distributions = []\n",
    "    for idx in sample_indices:\n",
    "        votes = []\n",
    "        for tree in rf.estimators_:\n",
    "            vote = tree.predict(X_test.iloc[idx:idx+1])[0]\n",
    "            votes.append(vote)\n",
    "        \n",
    "        movie_votes = votes.count(0)/len(votes)\n",
    "        tvshow_votes = votes.count(1)/len(votes)\n",
    "        vote_distributions.append([movie_votes, tvshow_votes])\n",
    "    \n",
    "    vote_df = pd.DataFrame(vote_distributions, \n",
    "                          columns=class_names,\n",
    "                          index=[f'Muestra {i+1}\\n(Real: {class_names[y_test.iloc[i]]})' \n",
    "                                 for i in sample_indices])\n",
    "    \n",
    "    vote_df.plot(kind='bar', stacked=True, ax=plt.gca(), colormap='coolwarm')\n",
    "    plt.title('Distribución de Votos para Predicciones Incorrectas', fontsize=14)\n",
    "    plt.xlabel('Muestras incorrectamente clasificadas')\n",
    "    plt.ylabel('Proporción de votos')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(title='Clase votada')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('random_forest_vote_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n✅ ¡Excelente! No hay predicciones incorrectas para visualizar la distribución de votos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded57c9",
   "metadata": {},
   "source": [
    "# 6. Evaluación y Validación\n",
    "\n",
    "Se utilizan métricas de evaluación para comparar el rendimiento de los tres modelos:\n",
    "\n",
    "- Accuracy (Precisión global): Representa la proporción de predicciones correctas (tanto verdaderos positivos como verdaderos negativos) respecto al total de predicciones realizadas. Se calcula como (TP + TN) / (TP + TN + FP + FN), donde TP son verdaderos positivos, TN verdaderos negativos, FP falsos positivos y FN falsos negativos. En este contexto, mide el porcentaje total de títulos clasificados correctamente como películas o series.\n",
    "- Precision (Precisión): Mide la proporción de predicciones positivas que son realmente correctas. Se calcula como TP / (TP + FP). En nuestro caso, para la categoría \"Movie\", indica qué porcentaje de los títulos clasificados como películas son realmente películas. Una alta precisión significa pocos falsos positivos (pocas series clasificadas erróneamente como películas).\n",
    "- Recall (Sensibilidad o Exhaustividad): Representa la proporción de instancias positivas reales que fueron identificadas correctamente. Se calcula como TP / (TP + FN). Para la categoría \"TV Show\", mide qué porcentaje de todas las series existentes fueron correctamente identificadas como tales. Un alto recall significa pocos falsos negativos (pocas series clasificadas erróneamente como películas).\n",
    "- F1-score: Es la media armónica entre la precisión y el recall, proporcionando una métrica balanceada que considera ambos aspectos. Se calcula como 2 * (Precision * Recall) / (Precision + Recall). Es especialmente útil cuando hay un desbalance en las clases o cuando se busca un equilibrio entre minimizar falsos positivos y falsos negativos.\n",
    "\n",
    "Estas métricas permiten determinar cuál algoritmo presenta mejor desempeño para este dataset, considerando no solo la precisión global sino también el equilibrio entre los diferentes tipos de errores de clasificación, lo cual es crucial para aplicaciones prácticas donde los costos de diferentes tipos de errores pueden variar significativamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a869e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KNN:\")\n",
    "print(classification_report(y_test, y_pred_knn, digits=10))\n",
    "\n",
    "print(\"Árbol ID3:\")\n",
    "print(classification_report(y_test, y_pred_id3, digits=10))\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf, digits=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30481361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    \"KNN\": {\n",
    "        \"precision\": 0.9979708323,\n",
    "        \"recall\":    0.9979708323,\n",
    "        \"f1\":        0.9979708323\n",
    "    },\n",
    "    \"ID3\": {\n",
    "        \"precision\": 0.9969562485,\n",
    "        \"recall\":    0.9969562485,\n",
    "        \"f1\":        0.9969562485\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"precision\": 0.9978510029,\n",
    "        \"recall\":    0.9991145218,\n",
    "        \"f1\":        0.9984800559\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "models = list(metrics.keys())\n",
    "\n",
    "precision_errors = [1 - metrics[m][\"precision\"] for m in models]\n",
    "recall_errors    = [1 - metrics[m][\"recall\"]    for m in models]\n",
    "f1_errors        = [1 - metrics[m][\"f1\"]        for m in models]\n",
    "\n",
    "\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(x - width, precision_errors, width, label='Error Precision')\n",
    "plt.bar(x,         recall_errors,    width, label='Error Recall')\n",
    "plt.bar(x + width, f1_errors,        width, label='Error F1-score')\n",
    "\n",
    "plt.xticks(x, models)\n",
    "plt.ylabel('Error (1 - métrica)')\n",
    "plt.title('Comparación de errores por modelo (valores ampliados)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562681b",
   "metadata": {},
   "source": [
    "# 7. Validación Cruzada para Evaluación Robusta de los Modelos\n",
    "\n",
    "La evaluación anterior se realizó utilizando una única división de los datos en conjuntos de entrenamiento y prueba. Para obtener una evaluación más robusta y confiable del rendimiento de los modelos, aplicamos validación cruzada k-fold, que permite utilizar todos los datos para entrenamiento y prueba en diferentes iteraciones, reduciendo la varianza en las métricas de evaluación y minimizando el riesgo de sobreajuste o subajuste debido a una partición específica de los datos.\n",
    "\n",
    "En este caso, utilizamos 5-fold cross-validation, donde los datos se dividen en 5 partes iguales. En cada iteración, 4 partes se utilizan para entrenar el modelo y la parte restante para evaluarlo. Este proceso se repite 5 veces, asegurando que cada muestra se utilice exactamente una vez para la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuración de la validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Métricas a evaluar\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1'\n",
    "}\n",
    "\n",
    "# Inicializar diccionario para almacenar resultados\n",
    "cv_results = {}\n",
    "\n",
    "# Modelos a evaluar\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'ID3': DecisionTreeClassifier(criterion=\"entropy\", max_depth=5, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "print(\"Ejecutando validación cruzada para todos los modelos...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Ejecutar validación cruzada para cada modelo\n",
    "for name, model in tqdm(models.items(), desc=\"Progreso de Validación Cruzada\"):\n",
    "    print(f\"\\nEvaluando modelo: {name}\")\n",
    "    \n",
    "    # Ejecutar cross-validation\n",
    "    results = cross_validate(\n",
    "        model, \n",
    "        X, \n",
    "        y, \n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        return_train_score=False,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Almacenar resultados\n",
    "    cv_results[name] = {\n",
    "        'accuracy': results['test_accuracy'],\n",
    "        'precision': results['test_precision'],\n",
    "        'recall': results['test_recall'],\n",
    "        'f1': results['test_f1']\n",
    "    }\n",
    "    \n",
    "    # Mostrar resultados por fold\n",
    "    print(f\"\\nResultados por fold para {name}:\")\n",
    "    for i in range(5):\n",
    "        print(f\"Fold {i+1}:\")\n",
    "        print(f\"  Accuracy:  {results['test_accuracy'][i]:.6f}\")\n",
    "        print(f\"  Precision: {results['test_precision'][i]:.6f}\")\n",
    "        print(f\"  Recall:    {results['test_recall'][i]:.6f}\")\n",
    "        print(f\"  F1-score:  {results['test_f1'][i]:.6f}\")\n",
    "    \n",
    "    # Mostrar promedios y desviaciones estándar\n",
    "    print(f\"\\nPromedio ± Desviación estándar para {name}:\")\n",
    "    print(f\"  Accuracy:  {np.mean(results['test_accuracy']):.6f} ± {np.std(results['test_accuracy']):.6f}\")\n",
    "    print(f\"  Precision: {np.mean(results['test_precision']):.6f} ± {np.std(results['test_precision']):.6f}\")\n",
    "    print(f\"  Recall:    {np.mean(results['test_recall']):.6f} ± {np.std(results['test_recall']):.6f}\")\n",
    "    print(f\"  F1-score:  {np.mean(results['test_f1']):.6f} ± {np.std(results['test_f1']):.6f}\")\n",
    "    print(\"-\"*40)\n",
    "\n",
    "# Convertir resultados a DataFrame para visualización\n",
    "results_df = []\n",
    "for model_name, metrics in cv_results.items():\n",
    "    for i in range(5):\n",
    "        results_df.append({\n",
    "            'Modelo': model_name,\n",
    "            'Fold': i+1,\n",
    "            'Accuracy': metrics['accuracy'][i],\n",
    "            'Precision': metrics['precision'][i],\n",
    "            'Recall': metrics['recall'][i],\n",
    "            'F1-score': metrics['f1'][i]\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_df)\n",
    "\n",
    "# Visualización de resultados\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# 1. Boxplot de F1-score para comparar modelos\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.boxplot(x='Modelo', y='F1-score', data=results_df, palette='Set2')\n",
    "sns.stripplot(x='Modelo', y='F1-score', data=results_df, color='black', alpha=0.4, size=4)\n",
    "plt.title('Distribución de F1-score por Modelo (5-fold CV)', fontsize=14)\n",
    "plt.ylabel('F1-score')\n",
    "plt.ylim(0.95, 1.0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 2. Gráfico de barras con promedios y error bars\n",
    "plt.subplot(2, 2, 2)\n",
    "metrics_avg = []\n",
    "for model_name, metrics in cv_results.items():\n",
    "    metrics_avg.append({\n",
    "        'Modelo': model_name,\n",
    "        'Accuracy': np.mean(metrics['accuracy']),\n",
    "        'Precision': np.mean(metrics['precision']),\n",
    "        'Recall': np.mean(metrics['recall']),\n",
    "        'F1-score': np.mean(metrics['f1'])\n",
    "    })\n",
    "\n",
    "metrics_avg_df = pd.DataFrame(metrics_avg)\n",
    "metrics_std_df = pd.DataFrame({\n",
    "    'Modelo': list(cv_results.keys()),\n",
    "    'Accuracy': [np.std(cv_results[model]['accuracy']) for model in cv_results.keys()],\n",
    "    'Precision': [np.std(cv_results[model]['precision']) for model in cv_results.keys()],\n",
    "    'Recall': [np.std(cv_results[model]['recall']) for model in cv_results.keys()],\n",
    "    'F1-score': [np.std(cv_results[model]['f1']) for model in cv_results.keys()]\n",
    "})\n",
    "\n",
    "metrics_melted = pd.melt(metrics_avg_df, id_vars='Modelo', var_name='Métrica', value_name='Valor')\n",
    "std_melted = pd.melt(metrics_std_df, id_vars='Modelo', var_name='Métrica', value_name='Desviación')\n",
    "\n",
    "sns.barplot(x='Modelo', y='Valor', hue='Métrica', data=metrics_melted, \n",
    "            palette='viridis', errorbar=None)\n",
    "plt.title('Métricas Promedio por Modelo (5-fold CV)', fontsize=14)\n",
    "plt.ylabel('Valor de la métrica')\n",
    "plt.ylim(0.95, 1.0)\n",
    "plt.legend(title='Métrica', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 3. Análisis de estabilidad (desviación estándar)\n",
    "plt.subplot(2, 2, 3)\n",
    "std_melted = std_melted[std_melted['Métrica'] == 'F1-score']\n",
    "sns.barplot(x='Modelo', y='Desviación', data=std_melted, palette='coolwarm')\n",
    "plt.title('Estabilidad de los Modelos (Desviación estándar del F1-score)', fontsize=14)\n",
    "plt.ylabel('Desviación estándar')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 4. Comparación detallada de F1-score por fold\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.lineplot(data=results_df, x='Fold', y='F1-score', hue='Modelo', \n",
    "             marker='o', linewidth=2.5, markersize=10, palette='Set2')\n",
    "plt.title('F1-score por Fold para cada Modelo', fontsize=14)\n",
    "plt.ylabel('F1-score')\n",
    "plt.ylim(0.95, 1.0)\n",
    "plt.grid(linestyle='--', alpha=0.7)\n",
    "plt.legend(title='Modelo', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cross_validation_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Análisis detallado de resultados\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANÁLISIS DETALLADO DE RESULTADOS DE VALIDACIÓN CRUZADA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Identificar el mejor modelo según F1-score promedio\n",
    "best_model = max(cv_results.keys(), \n",
    "                key=lambda x: np.mean(cv_results[x]['f1']))\n",
    "best_score = np.mean(cv_results[best_model]['f1'])\n",
    "best_std = np.std(cv_results[best_model]['f1'])\n",
    "\n",
    "print(f\"\\n🏆 MEJOR MODELO: {best_model}\")\n",
    "print(f\"F1-score promedio: {best_score:.6f} ± {best_std:.6f}\")\n",
    "\n",
    "print(\"\\n📊 ANÁLISIS COMPARATIVO:\")\n",
    "for model_name, metrics in cv_results.items():\n",
    "    f1_avg = np.mean(metrics['f1'])\n",
    "    f1_std = np.std(metrics['f1'])\n",
    "    acc_avg = np.mean(metrics['accuracy'])\n",
    "    acc_std = np.std(metrics['accuracy'])\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  • F1-score: {f1_avg:.6f} (±{f1_std:.6f})\")\n",
    "    print(f\"  • Accuracy: {acc_avg:.6f} (±{acc_std:.6f})\")\n",
    "    print(f\"  • Estabilidad: {'ALTA' if f1_std < 0.001 else 'MEDIA' if f1_std < 0.005 else 'BAJA'}\")\n",
    "    \n",
    "    # Análisis de consistencia\n",
    "    min_f1 = np.min(metrics['f1'])\n",
    "    max_f1 = np.max(metrics['f1'])\n",
    "    consistency = max_f1 - min_f1\n",
    "    \n",
    "    print(f\"  • Rango F1-score: [{min_f1:.6f}, {max_f1:.6f}] (Δ = {consistency:.6f})\")\n",
    "    if consistency < 0.001:\n",
    "        print(f\"    → Modelo muy consistente en todos los folds\")\n",
    "    elif consistency < 0.005:\n",
    "        print(f\"    → Modelo consistente con ligeras variaciones\")\n",
    "    else:\n",
    "        print(f\"    → Modelo presenta variaciones significativas entre folds\")\n",
    "\n",
    "# Análisis de sesgo-varianza\n",
    "print(\"\\n🔍 ANÁLISIS SESGO-VARIANZA:\")\n",
    "for model_name, metrics in cv_results.items():\n",
    "    f1_avg = np.mean(metrics['f1'])\n",
    "    f1_std = np.std(metrics['f1'])\n",
    "    \n",
    "    bias = 1 - f1_avg\n",
    "    variance = f1_std\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  • Sesgo (Bias): {bias:.6f}\")\n",
    "    print(f\"  • Varianza: {variance:.6f}\")\n",
    "    \n",
    "    if bias < 0.01 and variance < 0.001:\n",
    "        print(f\"    → Modelo ideal: bajo sesgo y baja varianza\")\n",
    "    elif bias < 0.01 and variance > 0.005:\n",
    "        print(f\"    → Alto riesgo de sobreajuste (overfitting)\")\n",
    "    elif bias > 0.01 and variance < 0.001:\n",
    "        print(f\"    → Alto riesgo de subajuste (underfitting)\")\n",
    "    else:\n",
    "        print(f\"    → Equilibrio razonable entre sesgo y varianza\")\n",
    "\n",
    "# Recomendaciones basadas en validación cruzada\n",
    "print(\"\\n💡 RECOMENDACIONES BASADAS EN VALIDACIÓN CRUZADA:\")\n",
    "best_model_f1 = max(cv_results.keys(), key=lambda x: np.mean(cv_results[x]['f1']))\n",
    "best_model_std = min(cv_results.keys(), key=lambda x: np.std(cv_results[x]['f1']))\n",
    "\n",
    "if best_model_f1 == best_model_std:\n",
    "    print(f\"  • {best_model_f1} es el mejor modelo tanto en rendimiento como en estabilidad\")\n",
    "else:\n",
    "    print(f\"  • {best_model_f1} tiene el mejor rendimiento promedio\")\n",
    "    print(f\"  • {best_model_std} es el modelo más estable (menor variación entre folds)\")\n",
    "\n",
    "if np.std(cv_results[best_model_f1]['f1']) > 0.002:\n",
    "    print(f\"  • Se recomienda ajustar hiperparámetros de {best_model_f1} para mejorar su estabilidad\")\n",
    "\n",
    "if 'Random Forest' in cv_results and np.mean(cv_results['Random Forest']['f1']) > 0.998:\n",
    "    print(\"  • Los resultados extremadamente altos sugieren que las características son muy predictivas\")\n",
    "    print(\"    para distinguir entre películas y series, lo que es consistente con el análisis EDA.\")\n",
    "\n",
    "# Tabla resumen para incluir en el informe\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABLA RESUMEN PARA INFORME\")\n",
    "print(\"=\"*70)\n",
    "summary_table = pd.DataFrame({\n",
    "    'Modelo': list(cv_results.keys()),\n",
    "    'F1-score Promedio': [np.mean(cv_results[model]['f1']) for model in cv_results.keys()],\n",
    "    'F1-score Std': [np.std(cv_results[model]['f1']) for model in cv_results.keys()],\n",
    "    'Accuracy Promedio': [np.mean(cv_results[model]['accuracy']) for model in cv_results.keys()],\n",
    "    'Accuracy Std': [np.std(cv_results[model]['accuracy']) for model in cv_results.keys()],\n",
    "})\n",
    "\n",
    "summary_table = summary_table.sort_values('F1-score Promedio', ascending=False)\n",
    "summary_table['F1-score Promedio'] = summary_table['F1-score Promedio'].apply(lambda x: f\"{x:.6f}\")\n",
    "summary_table['F1-score Std'] = summary_table['F1-score Std'].apply(lambda x: f\"{x:.6f}\")\n",
    "summary_table['Accuracy Promedio'] = summary_table['Accuracy Promedio'].apply(lambda x: f\"{x:.6f}\")\n",
    "summary_table['Accuracy Std'] = summary_table['Accuracy Std'].apply(lambda x: f\"{x:.6f}\")\n",
    "\n",
    "print(summary_table.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061d652",
   "metadata": {},
   "source": [
    "# 8. Conclusiones\n",
    "\n",
    "Tras aplicar la metodología KDD al conjunto de datos *Netflix Titles*, se comprobó que el problema de clasificación entre películas y series puede ser abordado mediante distintos algoritmos supervisados.\n",
    "\n",
    "Los resultados obtenidos indican que:\n",
    "\n",
    "- **KNN** presenta un rendimiento aceptable, aunque sensible a la cantidad de atributos.\n",
    "- **ID3** ofrece interpretabilidad, pero su exactitud es inferior al de modelos más robustos.\n",
    "- **Random Forest** obtuvo el mejor desempeño global, debido a su capacidad para reducir el sobreajuste y manejar gran cantidad de características categóricas transformadas.\n",
    "\n",
    "Aunque las métricas son muy elevadas para todos los modelos, la visualización de las tasas de error permite identificar de manera más clara que Random Forest presenta el menor error promedio, consolidándose como el mejor clasificador en este experimento.\n",
    "\n",
    "Por tanto, se concluye que **Random Forest** es el algoritmo más adecuado para este dataset, proporcionando un equilibrio óptimo entre precisión y generalización.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73561b4e",
   "metadata": {},
   "source": [
    "# 9. Bibliografía\n",
    "\n",
    "Fayyad, U., Piatetsky-Shapiro, G., & Smyth, P. (1996). *The KDD process for extracting useful knowledge from volumes of data*. Communications of the ACM, 39(11), 27–34.\n",
    "\n",
    "Han, J., Kamber, M., & Pei, J. (2011). *Data Mining: Concepts and Techniques* (3rd ed.). Morgan Kaufmann.\n",
    "\n",
    "Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., … Duchesnay, E. (2011). *Scikit-learn: Machine Learning in Python*. Journal of Machine Learning Research, 12, 2825–2830.\n",
    "\n",
    "Netflix Titles Dataset. (2020). *Kaggle*. Recuperado de https://www.kaggle.com/shivamb/netflix-shows\n",
    "\n",
    "Breiman, L. (2001). *Random forests*. Machine Learning, 45(1), 5–32.\n",
    "\n",
    "Cover, T., & Hart, P. (1967). *Nearest neighbor pattern classification*. IEEE Transactions on Information Theory, 13(1), 21–27.\n",
    "\n",
    "Quinlan, J. R. (1986). *Induction of decision trees*. Machine Learning, 1, 81–106.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06b6817",
   "metadata": {},
   "source": [
    "# 10. Recursos\n",
    "\n",
    "El repositorio del proyecto se encuentra en este enlace:\n",
    "\n",
    "🔗 **https://github.com/FrankHenkourth/KDD_Netflix**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdd_netflix (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
